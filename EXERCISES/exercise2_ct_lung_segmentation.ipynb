{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise2_ct_lung_segmentation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5NRwttRYghnk","colab_type":"text"},"source":["#Introduction\n","This tutorial covers the following topics:\n","*   Loading 3D images (NIFTI) as input to a CNN\n","*   Developing an encoder-decorder segmentation network (U-Net)\n","\n","The data used in this exercise includes CT images and lung contours downloaded from The Cancer Imaging Archive: \n","> _Yang, Jinzhong; Sharp, Greg; Veeraraghavan, Harini ; van Elmpt, Wouter ; Dekker, Andre; Lustberg, Tim; Gooding, Mark. (2017). Data from Lung CT Segmentation Challenge. The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2017.3r3fvz08_\n","\n","Three-dimensionsal CT images and lung contours/masks were converted into the NIFTI file format. CT images were normalized such (-1000 HU, 1000 HU) became (0, 1).  "]},{"cell_type":"markdown","metadata":{"id":"9GR8IBY1sps5","colab_type":"text"},"source":["Note: make sure your session is connected to a GPU. From the dropdown menu: __Runtime > Change Runtime Type > GPU (or TPU)__"]},{"cell_type":"markdown","metadata":{"id":"BH8Ffyc_FOM-","colab_type":"text"},"source":["#Data loading\n","First we need to download the data (hosted in cloud storage) into our Colab session. <br>\n","Then we untar and decompress it \"locally\" to our /home/ folder."]},{"cell_type":"code","metadata":{"id":"qfL4LXfenOSA","colab_type":"code","colab":{}},"source":["# download the data from the cloud\n","! wget -N https://f001.backblazeb2.com/file/snmmi-hands-on-ai/LCTSC_nii.tar.gz -P /home\n","\n","# this should take a few seconds, please be patient\n","print('decompressing...')\n","! tar xzf \"/home/LCTSC_nii.tar.gz\" --directory /home\n","print('done!')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMCiifr5Fprc","colab_type":"text"},"source":["Import some libraries. Nibabel is our library to handle NIFTI files"]},{"cell_type":"code","metadata":{"id":"ejSUhibpnO4J","colab_type":"code","colab":{}},"source":["import nibabel as nib\n","import numpy as np\n","import os\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UEAnDESFvPQ","colab_type":"text"},"source":["Each folder in /home/LCTSC_nii/  contains data for a different subject:\n","> /home/LCTSC_nii/  \n"," &nbsp;&nbsp;&nbsp;001/  \n"," &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ct.nii  \n"," &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask.nii  \n"," &nbsp;&nbsp;&nbsp;002/  \n"," &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ct.nii  \n"," &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask.nii  \n"," &nbsp;&nbsp;&nbsp;             ...\n","\n","Store paths to all subjects' data to a list, then randomize the orderering"]},{"cell_type":"code","metadata":{"id":"Xy6M0uYUoWSA","colab_type":"code","colab":{}},"source":["path_to_images='/home/LCTSC_nii'\n","subject_paths = [i.path for i in os.scandir(path_to_images) if i.is_dir()]\n","\n","#randomize order\n","random.seed(1)\n","random.shuffle(subject_paths)\n","print(subject_paths)\n","\n","#which subjects should be validation \n","#(note: careful not to include a subject's images in both train and validation)\n","validation_subjects = [0, 1, 2]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBFsqlTYKMfK","colab_type":"text"},"source":["Loop through each subject and do the following:\n","\n","\n","*   Read each subject's NIFTI images and masks\n","*   Resize them \n","*   Convert them into format of (samples, x_dim, y_dim, channels), treating each axial slice as a sample\n","*   Sort them into training and validation data sets\n","\n","Note: your projects will likely need an additional testing data set\n"]},{"cell_type":"code","metadata":{"id":"-2OcOYrgrUiO","colab_type":"code","colab":{}},"source":["#use CV2 to resample the images\n","from cv2 import resize, INTER_LINEAR, INTER_NEAREST\n","\n","resample_dims = 128\n","\n","#initialize arrays (can erase later, but probably doesn't matter)\n","train_images = np.zeros((1,resample_dims, resample_dims,1))\n","train_masks =  np.zeros((1,resample_dims, resample_dims,1))\n","val_images = np.zeros((1,resample_dims, resample_dims,1))\n","val_masks = np.zeros((1,resample_dims, resample_dims,1))\n","\n","#loop through, loading each subject's data\n","for i,subject in enumerate(subject_paths):\n","\n","  #read a subject's stack of 2D images and stack of 2D masks, resize\n","  image_stack_i = resize(nib.load(os.path.join(subject, 'ct.nii')).get_fdata(),(resample_dims,resample_dims), interpolation=INTER_LINEAR) \n","  mask_stack_i = resize(nib.load(os.path.join(subject, 'mask.nii')).get_fdata(),(resample_dims,resample_dims), interpolation=INTER_NEAREST)\n","  \n","  #rearrange the data from (x_dim, y_dim, samples) into (samples, x_dim, y_dim)  \n","  image_stack_i = np.moveaxis(image_stack_i, 2,0)\n","  mask_stack_i = np.moveaxis(mask_stack_i, 2,0)\n","\n","  #this adds the channels dimension (may seem strange, but it is needed)\n","  image_stack_i = image_stack_i[:,:,:,np.newaxis]\n","  mask_stack_i = mask_stack_i[:,:,:,np.newaxis]\n","\n","  #add images and masks, split into training and validation\n","  if i in validation_subjects:\n","    val_images = np.concatenate((val_images, image_stack_i), axis=0) \n","    val_masks = np.concatenate((val_masks, mask_stack_i), axis=0)\n","  else:\n","    train_images = np.concatenate((train_images, image_stack_i), axis=0) \n","    train_masks = np.concatenate((train_masks, mask_stack_i), axis=0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay1GZ9_OlqPG","colab_type":"code","colab":{}},"source":["print('Size of input images: ' + str(train_images.shape))\n","print('Size of input masks: ' + str(train_masks.shape))\n","print('Size of validation images: ' + str(val_images.shape))\n","print('Size of validation masks: ' + str(val_masks.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3tOTSaHMhT2","colab_type":"text"},"source":["Let's inspect the images, to make sure they look like what we expect (very important!). You can run this block many times with a random slice being shown each time it's run. "]},{"cell_type":"code","metadata":{"id":"GnHlpPjfZbU7","colab_type":"code","colab":{}},"source":["from matplotlib import pyplot as plt\n","# set plotting to be in-line\n","%matplotlib inline\n","\n","#view random slice, concatenating the image and mask next to each other\n","random_slice = random.randint(0,train_images.shape[0])\n","fig = plt.figure(figsize=(10,10))\n","plt.imshow(np.concatenate((train_images[random_slice,:,:,0], train_masks[random_slice,:,:,0]),axis=1), cmap='gray')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LtF-7eLND8E","colab_type":"text"},"source":["#Model building and training\n","First load some essential libraries for model building"]},{"cell_type":"code","metadata":{"id":"gHSh6PnHpnr5","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import UpSampling2D\n","from tensorflow.keras.layers import concatenate\n","# also, import the Model function for building the model\n","from tensorflow.keras import Model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcfsKu-nPOwR","colab_type":"text"},"source":["Build a 5-level encoder module (ie, 4 down-sampling steps) with skip connections to a mirror-image decoder module.\n","The number of filters can be altered -- this is a \"small\" version of the U-Net"]},{"cell_type":"code","metadata":{"id":"4pbb3XeE0vHp","colab_type":"code","colab":{}},"source":["# create our input layer by giving it an input shape\n","input_layer = Input(shape=train_images.shape[1:])\n","\n","#level 1\n","conv1_en = Conv2D(8, 3, activation = 'relu', padding = 'same')(input_layer)\n","pool1_en = MaxPooling2D(pool_size=(2, 2))(conv1_en)\n","#level 2\n","conv2_en = Conv2D(16, 3, activation = 'relu', padding = 'same')(pool1_en)\n","pool2_en = MaxPooling2D(pool_size=(2, 2))(conv2_en)\n","#level 3\n","conv3_en = Conv2D(32, 3, activation = 'relu', padding = 'same')(pool2_en)\n","pool3_en = MaxPooling2D(pool_size=(2, 2))(conv3_en)\n","#level 4\n","conv4_en = Conv2D(64, 3, activation = 'relu', padding = 'same')(pool3_en)\n","pool4_en = MaxPooling2D(pool_size=(2, 2))(conv4_en)\n","\n","#bottom level\n","conv_bottom = Conv2D(64, 3, activation = 'relu', padding = 'same')(pool4_en)\n","\n","#level 4 - DECODER\n","up4_dec = UpSampling2D(size = (2,2))(conv_bottom)\n","conv4_dec = concatenate([conv4_en,up4_dec])\n","conv4_dec = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv4_dec)\n","#level 3 - DECODER\n","up3_dec = UpSampling2D(size = (2,2))(conv4_dec)\n","conv3_dec = concatenate([conv3_en,up3_dec])\n","conv3_dec = Conv2D(32, 3, activation = 'relu', padding = 'same')(conv3_dec)\n","#level 2 - DECODER\n","up2_dec = UpSampling2D(size = (2,2))(conv3_dec)\n","conv2_dec = concatenate([conv2_en,up2_dec])\n","conv2_dec = Conv2D(16, 3, activation = 'relu', padding = 'same')(conv2_dec)\n","#level 1 - DECODER\n","up1_dec = UpSampling2D(size = (2,2))(conv2_dec)\n","conv1_dec = concatenate([conv1_en,up1_dec])\n","conv1_dec = Conv2D(8, 3, activation = 'relu', padding = 'same')(conv1_dec)\n","\n","#output level\n","conv_out = Conv2D(8, 3, activation = 'relu', padding = 'same')(conv1_dec)\n","conv_out = Conv2D(1, 3, activation = 'sigmoid', padding='same')(conv_out)\n","\n","#define inputs/outpus\n","unet = Model(inputs = input_layer, outputs = conv_out)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1bs3-OVTNVd","colab_type":"text"},"source":["Inspect the model"]},{"cell_type":"code","metadata":{"id":"FOsyBNEFMOPv","colab_type":"code","colab":{}},"source":["#show model summary\n","unet.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnqMFcLY9N2I","colab_type":"code","colab":{}},"source":["#you can also create a figure\n","from tensorflow.keras.utils import plot_model\n","plot_model(unet, show_shapes=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5UmZx5RHTQNt","colab_type":"text"},"source":["Compile and train the model. All the training results get stored in _history_ variable"]},{"cell_type":"code","metadata":{"id":"4nlubPZ8MP77","colab_type":"code","colab":{}},"source":["from tensorflow.keras import optimizers\n","\n","#I tried several combinations, RMSprop with lr=0.001 worked for me\n","unet.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=0.001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZW6zp9JLT9tF","colab":{}},"source":["history = unet.fit(x=train_images, y=train_masks,\n","          batch_size=32,\n","          epochs=10,\n","          verbose=1,\n","          shuffle=True,\n","          validation_data=(val_images, val_masks))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CGMiqViJTjR8","colab_type":"text"},"source":["Now inspect the results. First look at the loss plot. Change the _plt.ylim_ as appropriate"]},{"cell_type":"code","metadata":{"id":"7gIkfUTmcOsF","colab_type":"code","colab":{}},"source":["# Plot the losses that are stored in the 'hist' variable\n","plt.figure(figsize=(10,10));\n","plt.plot(history.epoch,history.history['loss'],'b-s')\n","plt.plot(history.epoch,history.history['val_loss'],'r-s')\n","plt.legend(['Training Loss',\n","            ' Validation Loss'])\n","plt.xlabel('Epochs')\n","plt.ylabel('Binary Crossentropy')\n","plt.ylim([0,0.1])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BRmKRXhMTsdS","colab_type":"text"},"source":["Show the images with the results. First run the unet  model using our validation images as input. Then show the input image next to the ground truth mask and the predicted mask."]},{"cell_type":"code","metadata":{"id":"_fNh2qndnIE7","colab_type":"code","colab":{}},"source":["#apply the unet to our validation images\n","predictions = unet.predict(val_images, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEuWrrice0M5","colab_type":"code","colab":{}},"source":["#show random images with the predicted results\n","random_slice = random.randint(0,val_images.shape[0])\n","fig = plt.figure(figsize=(10,10))\n","im_slice = val_images[random_slice,:,:,0]\n","true_mask_slice = val_masks[random_slice,:,:,0]\n","pred_mask_slice = predictions[random_slice,:,:,0]\n","plt.imshow(np.c_[im_slice, true_mask_slice, np.round(pred_mask_slice)], cmap='gray')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmjCtB5qdV_4","colab_type":"code","colab":{}},"source":["#save your model (optional)\n","unet.save('/home/unet_lung_segmation_model.hdf5')"],"execution_count":0,"outputs":[]}]}